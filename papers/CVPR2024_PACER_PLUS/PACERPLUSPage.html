
<!DOCTYPE html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1.5px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios</title>
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:30px">PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios</span>
	</center>

	<br>


  	<table align=center width=900px>
  	 <tr>
		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="http://wangjingbo.top">Jingbo Wang<sup>1</sup></a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://www.zhengyiluo.com/">Zhengyi Luo<sup>2</sup></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://ye-yuan.com/">Ye Yuan<sup>3</sup></a></span>
		</center>
		</td>

		<td align=center width=80px>
			<center>
			<span style="font-size:18px"><a href="https://yixuanli98.github.io/">Yixuan Li<sup>4</sup></a></span>
			</center>
		</td>
		<td align=center width=80px>
			<center>
			<span style="font-size:18px"><a href="https://daibo.info/">Bo Dai<sup>1</sup></a></span>
			</center>
		</td>
	 </tr>
	</table>

	<br>


	<table align=center width=1100px>
  	 <tr>
        <td align=center width=120px>
            <center>
            <span style="font-size:20px">1.Shanghai AI LAB</span>
            </center>
        </td>

		<td align=center width=80px>
		<center>
		<span style="font-size:20px">2.CMU</span>
		</center>
		</td>
		<td align=center width=80px>
			<center>
			<span style="font-size:20px">3.Nvidia</span>
			</center>
		</td>
			<td align=center width=80px>
				<center>
				<span style="font-size:20px">2.CUHK</span>
				</center>
			</td>
	 </tr>
	</table>
	<br>
	<table align=left width=1100px>
		<tr>
		 <td align=left width=120px>
			 <left>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<span style="font-size:15px">Any questions are welcome to email Jingbo Wang: wangjingbo1219@gmail.com</span>
			 </left>
		 </td>

	  </tr>
	 </table>

	<br>
	<hr>
	<table align=center width=1100px>
		<tr>
			<td>
			<left>
		<left><h3>News</h3></left>
		<p class="lead"><font color="red">[news]</font>  The paper is accepted by CVPR 2024. We release codes and pre-trained models in our <a href="https://github.com/IDC-Flash/PacerPlus">PacerPlus</a> . </p>
	</left>
	</td>
	</tr>
	</table>
	<hr>
	<br>



  		  <table align=center width=900px>
  			  <tr>
  	              <td width=900px>
  					<center>
  	                	<a href="papers/CVPR2024_PACER_PLUS/cvpr_2024_framework.png"><img src = "papers/CVPR2024_PACER_PLUS/cvpr_2024_framework.png" height="200px"></img></href></a><br>
					</center>
  	              </td>
  	          </tr>
  		  </table>

      	  <br>
      	  <p style="text-align:justify">
			We address the challenge of content diversity and controllability in pedestrian simulation for driving scenarios.
			Recent pedestrian animation frameworks have a significant limitation wherein they primarily focus on either following
			trajectory [46] or the content of the reference video [57], consequently overlooking the potential diversity of human
			motion within such scenarios. This limitation restricts the ability to generate pedestrian behaviors that exhibit a wider
			range of variations and realistic motions and therefore restricts its usage to provide rich motion content for other
			components in the driving simulation system, e.g., suddenly changed motion to which the autonomous vehicle should
			respond. In our approach, we strive to surpass the limitation by showcasing diverse human motions obtained from
			various sources, such as generated human motions, in addition to following the given trajectory. The fundamental
			contribution of our framework lies in combining the motion tracking task with trajectory following, which enables the
			tracking of specific motion parts (e.g., upper body) while simultaneously following the given trajectory by a single
			policy. This way, we significantly enhance both the diversity of simulated human motion within the given scenario
			and the controllability of the content, including languagebased control. Our framework facilitates the generation of
			a wide range of human motions, contributing to greater realism and adaptability in pedestrian simulations for driving
			scenarios    	  
		 </p>
		 <br>
  		<hr>
		   <table align=center width=1100>
	 		<center><h1>Demo Video</h1></center>
	 		<center>
				<iframe width="800" height="450" src="https://youtu.be/Pq10Q_ZBOrw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

	
  		  <br>
		  <hr>
		 <!-- <table align=center width=550px> -->
  		  <!-- <table align=center width=1100>
	 		<center><h1>Paper</h1></center>
  			  <tr>
  	              <!--<td width=300px align=left>-->
  	              <!-- <a href="http://arxiv.org/pdf/1603.08511.pdf"> -->
				  <!-- <td><a href="#"><img class="layered-paper-big" style="height:175px" src="./resources/images/paper.png"/></a></td> -->
				  <!-- <td><a href="https://arxiv.org/pdf/2004.13985.pdf"><img style="height:180px" src="./pages.png"/></a></td>
				  <td><span style="font-size:14pt"></span><a href="https://arxiv.org/pdf/2004.13985.pdf">Motion Guided 3D Pose Estimation from Videos</a><br><br>
                    <i>Jingbo Wang, Sijie Yan, Yuanjun Xiong, and Dahua Lin</i><br><br>
					European Conference on Computer Vision (ECCV), 2020
					</td>
					</td>
              </tr>
  		  </table> --> -->

		

  			  <!-- 分界线  引用 -->
		  <hr/>
  		  <!-- <table align=center width=1100px>
  			  <tr>
  	              <td>
  				<left>
				<center><h1>BibTex</h1></center>
	  		  @article{wang2020motion, <br>
				&nbsp;&nbsp;&nbsp;&nbsp; title={Motion Guided 3D Pose Estimation from Videos}, <br>
				&nbsp;&nbsp;&nbsp;&nbsp; author={Wang, Jingbo and Yan, Sijie and Xiong, Yuanjun and Lin, Dahua}, <br>
				&nbsp;&nbsp;&nbsp;&nbsp; inproceedings={ECCV},<br>
				&nbsp;&nbsp;&nbsp;&nbsp; year={2020}<br>
			  }

			</left>
		</td>
		</tr>
		</table> -->
		<br>




		  <!-- 分界线 -->
  		  <!-- <hr>
  		  <table align=center width=1100px>
  			  <tr>
  	              <td>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
	  		  We would like to thank Yichao Xu in A*STAR for insightful discussion.
			</left>
		</td>
		</tr>
		</table>
		<br> -->
</body>
</html>
