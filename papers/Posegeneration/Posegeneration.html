
<!DOCTYPE html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1.5px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Scene-aware Generative Network for Human Motion Synthesis </title>
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:30px">Scene-aware Generative Network for Human Motion Synthesis</span>
	</center>

	<br>


  	<table align=center width=900px>
  	 <tr>
		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="http://wangjingbo.top">Jingbo Wang<sup>1</sup></a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://scholar.google.co.uk/citations?user=tAgSyxIAAAAJ&hl=en">Sijie Yan<sup>1</sup></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="http://daibo.info">Bo Dai<sup>2</sup></a></span>
		</center>
		</td>

		<td align=center width=80px>
			<center>
			<span style="font-size:18px"><a href="http://dahua.me/">Dahua Lin<sup>1</sup></a></span>
			</center>
		</td>
	 </tr>
	</table>

	<br>


	<table align=center width=1100px>
  	 <tr>
        <td align=center width=120px>
            <center>
            <span style="font-size:20px">1.The Chinese University of Hong Kong</span>
            </center>
        </td>

		<td align=center width=80px>
		<center>
		<span style="font-size:20px">2.Nanyang Technological University</span>
		</center>
		</td>
	 </tr>
	</table>
	<br>
	<table align=left width=1100px>
		<tr>
		 <td align=left width=120px>
			 <left>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<span style="font-size:15px">Any questions are welcome to email Jingbo Wang: wj020@ie.cuhk.edu.hk</span>
			 </left>
		 </td>

	  </tr>
	 </table>

	<!-- <br>
	<hr>
	<table align=center width=1100px>
		<tr>
			<td>
			<left>
		<left><h3>News</h3></left>
		<p class="lead"><font color="red">[news]</font> (2020.07.03) The paper is accepted by ECCV 2020. We'll release codes and pre-trained models in our <a href="https://github.com/open-mmlab/mmskeleton">MMSkeleton</a> . </p>
	</left>
	</td>
	</tr>
	</table>
	<hr>
	<br> -->



  		  <table align=center width=900px>
  			  <tr>
  	              <td width=900px>
  					<center>
  	                	<a href="./arch.png"><img src = "./arch.png" height="400px"></img></href></a><br>
					</center>
  	              </td>
  	          </tr>
  		  </table>

      	  <br>
      	  <p style="text-align:justify">
			We revisit human motion synthesis, a task useful in various real-world applications,
			in this paper. Whereas a number of methods have been developed previously for this task, 
			they are often limited in two aspects: 1) focus on the poses while leaving the location movement behind, and 
			2) ignore the impact of the environment on the human motion. In this paper, we propose a new framework, with the interaction between
			the scene and the human motion is taken into account.
			Considering the uncertainty of human motion, we formulate this task
			as a generative task, whose objective is to generate plausible human 
			motion conditioned on both the scene and the human's initial position. 
			This framework factorizes the distribution of human motions
			into a distribution of movement trajectories conditioned on scenes and 
			that of body pose dynamics conditioned on both scenes and trajectories.
			We further derive a GAN-based learning approach, 
			with discriminators to enforce the compatibility 
			between the human motion and the contextual scene as well as 
			the 3D-to-2D projection constraints.   	  
		 </p>
		 <br>
  		<hr>
		   <table align=center width=1100>
	 		<center><h1>Demo Video</h1></center>
	 		<center>
				<iframe width="800" height="450" src="https://www.youtube.com/embed/XfA3QWcV0ik" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>		<hr/>
		<table align=center width=1100px>
			<tr>
			<td>
			<left>
					<center><h1>BibTex</h1></center>
					@article{wang2020motion, <br>
					&nbsp;&nbsp;&nbsp;&nbsp; title={Scene-aware Generative Network for Human Motion Synthesis}, <br>
					&nbsp;&nbsp;&nbsp;&nbsp; author={Wang, Jingbo and Yan, Sijie and Dai, Bo and Lin, Dahua}, <br>
					&nbsp;&nbsp;&nbsp;&nbsp; inproceedings={CVPR},<br>
					&nbsp;&nbsp;&nbsp;&nbsp; year={2021}<br>
				  }
	
				</left>
			</td>
			</tr>
			</table>
			<br>
	

</body>
</html>
