
<!DOCTYPE html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1.5px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Motion Guided 3D Pose Estimation from Videos </title>
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:30px">Motion Guided 3D Pose Estimation from Videos</span>
	</center>

	<br>


  	<table align=center width=900px>
  	 <tr>
		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="wangjingbo.top">Jingbo Wang<sup>1</sup></a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://scholar.google.co.uk/citations?user=tAgSyxIAAAAJ&hl=en">Sijie Yan<sup>1</sup></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="http://yjxiong.me/">Yuanjun Xiong<sup>2</sup></a></span>
		</center>
		</td>

		<td align=center width=80px>
			<center>
			<span style="font-size:18px"><a href="http://dahua.me/">Dahua Lin<sup>1</sup></a></span>
			</center>
		</td>
	 </tr>
	</table>

	<br>


	<table align=center width=1100px>
  	 <tr>
        <td align=center width=120px>
            <center>
            <span style="font-size:20px">1.The Chinese University of Hong Kong</span>
            </center>
        </td>

		<td align=center width=80px>
		<center>
		<span style="font-size:20px">2.Amazon/AWS AI</span>
		</center>
		</td>
	 </tr>
	</table>
	<br>
	<table align=left width=1100px>
		<tr>
		 <td align=left width=120px>
			 <left>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<span style="font-size:15px">Any questions are welcome to email Jingbo Wang: jbwang@ie.cuhk.edu.hk</span>
			 </left>
		 </td>

	  </tr>
	 </table>

	<br>
	<hr>
	<table align=center width=1100px>
		<tr>
			<td>
			<left>
		<left><h3>News</h3></left>
		<p class="lead"><font color="red">[news]</font> (2020.07.03) The paper is accepted by ECCV 2020. We'll release codes and pre-trained models in our <a href="https://github.com/open-mmlab/mmskeleton">MMSkeleton</a> . </p>
	</left>
	</td>
	</tr>
	</table>
	<hr>
	<br>



  		  <table align=center width=900px>
  			  <tr>
  	              <td width=900px>
  					<center>
  	                	<a href="./arch_1.png"><img src = "./arch_1.png" height="200px"></img></href></a><br>
					</center>
  	              </td>
  	          </tr>
  		  </table>

      	  <br>
      	  <p style="text-align:justify">
			We propose a new loss function, called motion loss, for the
			problem of monocular 3D Human pose estimation from videos. In computing motion loss, a simple yet effective representation for keypoint
			motion, called pairwise motion encoding, is introduced. We design a
			new graph convolutional network architecture, U-shaped GCN (UGCN).
			It captures both short-term and long-term motion information to fully
			leverage the additional supervision from the motion loss. We experiment
			training UGCN with the motion loss on two large scale benchmarks:
			Human3.6M and MPI-INF-3DHP. Our model surpasses other state-ofthe-art models by a large margin. It also demonstrates strong capacity
			in producing smooth 3D sequences and recovering keypoint motion.      	  
		 </p>
		 <br>
  		<hr>
		   <table align=center width=1100>
	 		<center><h1>Demo Video</h1></center>
	 		<center>
				<iframe width="800" height="450" src="https://www.youtube.com/embed/VHhsXG6OXnI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

	
  		  <br>
		  <hr>
		 <!-- <table align=center width=550px> -->
  		  <table align=center width=1100>
	 		<center><h1>Paper</h1></center>
  			  <tr>
  	              <!--<td width=300px align=left>-->
  	              <!-- <a href="http://arxiv.org/pdf/1603.08511.pdf"> -->
				  <!-- <td><a href="#"><img class="layered-paper-big" style="height:175px" src="./resources/images/paper.png"/></a></td> -->
				  <td><a href="arxiv"><img style="height:180px" src="./pages.png"/></a></td>
				  <td><span style="font-size:14pt"></span><a href="https://arxiv.org/pdf/2004.13985.pdf">Motion Guided 3D Pose Estimation from Videos</a><br><br>
                    <i>Jingbo Wang, Sijie Yan, Yuanjun Xiong, and Dahua Lin</i><br><br>
					European Conference on Computer Vision (ECCV), 2020
					</td>
					</td>
              </tr>
  		  </table>

		

  			  <!-- 分界线  引用 -->
		  <hr/>
  		  <table align=center width=1100px>
  			  <tr>
  	              <td>
  				<left>
				<center><h1>BibTex</h1></center>
	  		  @article{wang2020motion, <br>
				&nbsp;&nbsp;&nbsp;&nbsp; title={Motion Guided 3D Pose Estimation from Videos}, <br>
				&nbsp;&nbsp;&nbsp;&nbsp; author={Wang, Jingbo and Yan, Sijie and Xiong, Yuanjun and Lin, Dahua}, <br>
				&nbsp;&nbsp;&nbsp;&nbsp; journal={arXiv preprint arXiv:2004.13985},<br>
				&nbsp;&nbsp;&nbsp;&nbsp; year={2020}<br>
			  }

			</left>
		</td>
		</tr>
		</table>
		<br>




		  <!-- 分界线 -->
  		  <!-- <hr>
  		  <table align=center width=1100px>
  			  <tr>
  	              <td>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
	  		  We would like to thank Yichao Xu in A*STAR for insightful discussion.
			</left>
		</td>
		</tr>
		</table>
		<br> -->
</body>
</html>
