<!DOCTYPE html>

<html lang="en">
<head>
    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://scholar.google.co.uk/citations?user=GStTsxAAAAAJ&hl=en"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-156699410-1');
    </script>
    
    <meta charset="UTF-8">
    <meta http-equiv="Content-Security-Policy" content="block-all-mixed-content">

    <title>Jingbo Wang 王靖博</title>
    <link rel="icon"  href="images/icon.jpeg" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="css/style.css">
</head>

<div class="navbar navbar-fixed-top">
    <div class="container">
        <strong class="navbar-brand">Jingbo Wang / 王靖博</strong>
        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">

                <!-- <li><a href="#honors">Honors</a></li> -->
            </ul>
        </div>
    </div>
</div>

<div class="gray-container" id="about">
    <div class="container">
        <div class="row">
            <div class="col-xs-4">
                <img id="me-img" src="images/jingbo.jpg" width='512'>

                <div style="margin-top: 10%; font-size: large";><strong>Jingbo Wang/ 王靖博</strong></div>
                <div style="margin-top: 5%">   <a href="mailto:wangjingbo@pjlab.org.cn">wangjingbo@pjlab.org.cn</a> </div>
            </div>
            <div class="col-xs-8">
                <h2>
                    <strong>Jingbo Wang</strong>
                    <a href="cv-homepage.pdf" target="_blank">
                        <img src = "images/icon/cv.png" title = "cv" width ="36" height = "36">
                    </a>
                </h2>

                <p>
                    I lead the research team on humanoid robot learning at the Embodied AI Center of Shanghai AI Lab.
                    The goal of our research is to enable humanoid robots to learn and adapt to complex environments automatically with human knowledge.
                    Before that, I also did research on character animation/simulation, efficient preception models (A.K.A BiseNet V1/V2) and 3D reconstunction.
                </p>

                <div>
                    <div id="news"><img src="images/icon/news.png" title="news" width="24" height="24"> News</div>
                    <div class="row work-block">
                        <ul>
                            <li>
                                <b>Our team is hiring!</b> We are looking for talented full time researchers, reserch engineers and self-motivated interns to join us. If you have a strong background in following topics, please feel free to reach out to me.
                                <ul>
                                    <li> Humanoid Locomotion, Whole Body Control, Motion Tracking, Humanoid-Scene Interactions, Loco-Manipulation</li>
                                    <li> Behavior Foundation Model on Manipulation and Whole Body Control</li>
                                    <li> Character Animation, Motion Generation and Planning, Motion Retargeting</li>
                                    <li> Reinforcement learning, Efficient Generative Model, MLLM</li>
                                    <li> Real-time Perception and its Deployment</li>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<div id="rows" style="margin-left: 8%">


<div id="publication">
    <div class="container">
        <h2 class="section_title">Recent Research Interests
            <a href="https://scholar.google.co.uk/citations?user=GStTsxAAAAAJ&hl=en" target="_blank">
                    (<img src = "images/icon/scholar.jpg" title = "scholar" width ="28"> Full List in Google Scholar)
            </a>
        </h2>
        <!-- Paper TOKENHSI+-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/CVPR2025_TOKENHSI/TokenHSI.png", width=20%>
            </div>
            <div class="col-xs-8">
                Liang Pan, Zeshi Yang, Zhiyang Dou, Wenjia Wang, Buzhen Huang, Bo Dai, Taku Komura, <u>Jingbo Wang</u>
                <strong>TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization
                </strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2025</em>
                <br>
                [<a href="https://liangpan99.github.io/TokenHSI/" target="_blank">Project</a>]
                [<a href="https://arxiv.org/pdf/2503.19901" target="_blank">Paper</a>]
                <br>
            </div>
        </div>
        <!-- Paper SCMO+-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/CVPR2025_SCAMO/ScaMo.png", width=20%>
            </div>
            <div class="col-xs-8">
                Shunlin Lu, <u>Jingbo Wang</u>, Zeyu Lu, Ling-Hao Chen, Wenxun Dai, Junting Dong, Zhiyang Dou, Bo Dai, Ruimao Zhang
                <br>
                <strong>ScaMo: Exploring the Scaling Law in Autoregressive Motion Generation Model
                </strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2025</em>
                <br>
                [<a href="https://shunlinlu.github.io/ScaMo/" target="_blank">Project</a>]
                [<a href="https://arxiv.org/pdf/2412.14559" target="_blank">Paper</a>]
                <br>
            </div>
        </div>
        <!-- Paper COOHOI+-->
         <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/NEURIPS2024_COOHOI/coohoi.jpg", width=20%>
            </div>
            <div class="col-xs-8">
                Jiawei Gao*, Ziqin Wang*, Zeqi Xiao, Jingbo Wang, Tai Wang, Jinkun Cao, Xiaolin Hu†, Si Liu, Jifeng Dai, Jiangmiao Pang ('*' donats equal contribution.)
                <br>
                <strong>CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics
                </strong>
                <br>
                <em><i>Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024</em>
                <br>
                [<a href="https://gao-jiawei.com/Research/CooHOI/" target="_blank">Project</a>]
                [<a href="https://arxiv.org/abs/2406.14558v2" target="_blank">Paper</a>]
                <br>
            </div>
        </div>
        <!-- Paper PCACER+-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/CVPR2024_PACER_PLUS/cvpr_2024_sub.png", width=20%>
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>*, Zhengyi Luo*, Ye Yuan, Yixuan Li, Bo Dai ('*' donats equal contribution.)
                <br>
                <strong>PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios</strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2024</em>
                <br>
                [<a href="papers/CVPR2024_PACER_PLUS/PACERPLUSPage.html" target="_blank">Project</a>]
                [<a href="papers/CVPR2024_PACER_PLUS/pacer_plus.pdf" target="_blank">Paper</a>]
                [<a href="papers/CVPR2024_PACER_PLUS/demo_1_compress.mp4" target="_blank">Video</a>]
                <br>
            </div>
        </div>
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/SIGGRAPH2024_AMDM/comodo.png", width=20%>
            </div>
            <div class="col-xs-8">
                Yi Shi, <u>Jingbo Wang</u>, Xuekun Jiang, Bingkun Lin, Bo Dai, Xue Bin Peng
                <br>
                <strong>Interactive Character Control with Auto-Regressive Motion Diffusion Models</strong>
                <br>
                <em><i>ACM Transactions on Graphics (<strong>Proc. SIGGRAPH 2024)</strong>)</i>, 2024</em>
                <br>
                [<a href="https://xbpeng.github.io/projects/AMDM/AMDM_2024.pdf" target="_blank">Paper</a>]
                [<a href="https://yi-shi94.github.io/amdm_page/" target="_blank">Project</a>]
                <br>
            </div>
        </div>

        <!-- Paper ICLR 2024-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/ICLR2024_COC/unihsi.png", width=20%>
            </div>
            <div class="col-xs-8">
                Zeqi Xiao, Tai Wang, <u>Jingbo Wang</u>, Jinkun Cao, Wenwei Zhang, Bo Dai, Dahua Lin, Jiangmiao Pang
                <br>
                <strong>Unified Human-Scene Interaction via Prompted Chain-of-Contacts</strong>
                <br>
                <em><i>The International Conference on Learning Representations (<strong>ICLR</strong>)</i>, 2024</em>
                <br>
                [<a href="https://github.com/OpenRobotLab/UniHSI/blob/main/assets/UniHSI.pdf" target="_blank">Paper</a>]
                [<a href="https://xizaoqu.github.io/unihsi/" target="_blank">Project</a>]
                <br>
            </div>
        </div>
        <!-- Paper ICCV 2023-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/ICCV2023_Drive/iccv_2023.png", width=20%>
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>, Ye Yuan, Zhengyi Luo, Kevin Xie, Dahua Lin, Umar Iqbal,
                Sanja Fidler, Sameh Khamis
                <br>
                <strong>Learning Human Dynamics in Autonomous Driving Scenarios </strong>
                <br>
                <em><i>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2023</em>
                <br>
                [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.pdf" target="_blank">Paper</a>]
                [<a href="https://youtu.be/QTQtIDQVJ1I" target="_blank">Video</a>]

                <br>
            </div>
        </div>


<div id="education">
    <div class="container">
        <h2 class="section_title">Education</h2>
        <div class="row work-block">
            <ul>
                <li>[2020.08-2023.08] &nbsp; Ph.D student at MMLab, IE Department, The Chinese University of Hong Kong.
                <li>[2016.09-2019.07] &nbsp; Key Laboratory of Machine Perception (MOE), School of EECS, Peking University.
                <li>[2012.09-2016.07] &nbsp; Beijing Institute of Technology, School of Mathematics and Statistics.
            </ul>
        </div>
    </div>
</div>

<div id="experiences">
    <div class="container">
        <h2 class="section_title">Experiences</h2>
        <div class="row work-block">
            <ul>
                <li>[2022.05-2023.06] &nbsp; Research Intern at Nvidia Toronto AI Lab. Supervised by Dr Ye Yuan, Dr Sameh Khamis, and Prof. Sanja Filder</a>.
                <li>[2022.01-2022.05] &nbsp; Research Intern at Shanghai AI Lab. Supervised by Dr. Bo Dai</a>.
                <li>[2020.01-2021.12] &nbsp; Research Intern at SenseTime Research. Supervised by Dr. Ding Liang.
                <li>[2019.08-2020.07] &nbsp; Research Assistant at MMLAB, CUHK. Supervised by Prof. Dahua Lin.
                <li>[2017.06-2018.12] &nbsp; Research Intern at  Megvii Research. Supervise by Dr, Gang Yu.
            </ul>
        </div>
    </div>
</div>

<div id="academic competition">
<div class="container">
    <h2 class="section_title">Academic Competition</h2>
    <div class="row work-block">
        <ul>
            <li><div style="float:left; text-align:left"> <strong>Winner</strong> of COCO 2018 Challenge in Panoptic Segmentation Track </div> </li>
            <li><div style="float:left; text-align:left"> <strong>Winner</strong> of Mapillary 2018 Challenge in Panoptic Segmentation Track </div>
        </ul>
    </div>
</div>
</div>


<div id="footer">
    <div id="footer-text"></div>
</div>



<div class="container footer">
    <div class="row">
        <div class="text-center">
        Jingbo Wang @2020 &nbsp;&nbsp;&nbsp;&nbsp; Total Visitors:
        <a href='https://www.counter12.com'><img src='https://www.counter12.com/img-xWZ216Z86zx2AZbb-77.gif' border='0' alt='web counter free'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=xWZ216Z86zx2AZbb'></script></div> 
    </div>
</div>



</body>
</html>
