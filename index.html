<!DOCTYPE html>

<html lang="en">
<head>
    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://scholar.google.co.uk/citations?user=GStTsxAAAAAJ&hl=en"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-156699410-1');
    </script>
    
    <meta charset="UTF-8">
    <meta http-equiv="Content-Security-Policy" content="block-all-mixed-content">

    <title>Jingbo Wang 王靖博</title>
    <link rel="icon"  href="images/icon.jpeg" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="css/style.css">
</head>

<div class="navbar navbar-fixed-top">
    <div class="container">
        <strong class="navbar-brand">Jingbo Wang / 王靖博</strong>
        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="#about">About</a></li>
                <li><a href="#publication">Publications</a></li>
                <li><a href="#education">Education</a></li>
                <li><a href="#experiences">Experiences</a></li>
                <li><a href="#academic competition">Competition</a></li>
                <li><a href="#professional activities"> Activities</a></li>


                <!-- <li><a href="#honors">Honors</a></li> -->
            </ul>
        </div>
    </div>
</div>

<div class="gray-container" id="about">
    <div class="container">
        <div class="row">
            <div class="col-xs-4">
                <img id="me-img" src="images/wjb.png">

                <div style="margin-top: 10%; font-size: large";><strong>Jingbo Wang/ 王靖博</strong></div>
                <div style="margin-top: 5%"> Ph.D Student at The Chinese University of Hong Kong</div>
                <div style="margin-top: 5%">  wj020@ie.cuhk.edu.hk </div>
            </div>
            <div class="col-xs-8">
                <h2>
                    <strong>Jingbo Wang</strong>
                    <a href="wangjingbo1219.github.io/cv-homepage.pdf" target="_blank">
                        <img src = "images/icon/cv.png" title = "cv" width ="36" height = "36">
                    </a>
                    <a href="https://github.com/wangjingbo1219" target="_blank">
                        <img src = "images/icon/github_square.png" title = "github" width ="24">
                    </a>
                    <!-- <a href="https://www.linkedin.com/in/%E5%B0%8F%E5%BA%B7-%E9%99%88-03a149120/" target="_blank">
                        <img src = "images/icon/linkedin.png" title = "linkedin" width ="24">
                    </a> -->
                </h2>

                <p>
                <img src="images/icon/education.png" title="education" width="24" height="24">  
                I am currently a first-year Ph.D student at The Chinese University of Hong Kong (<a href="http://mmlab.ie.cuhk.edu.hk/"> MMLAB </a>), 
                supervised by <a href="http://dahua.me/"> Prof. Dahua Lin</a>. Before that, I received my Master degree from Peking University in 2019,
                supervised by <a href="https://scholar.google.com/citations?user=RuHyY6gAAAAJ&hl=zh-CN"> Researcher Gang Zeng</a> and my Bachelor degree from Beijing Institute of Technology in July 2016.
                <br/>
                </p>

                <br/>
                <p>
                <img src="images/icon/thought.png" title="thoughts" width="24" height="24"> 
                Now, my research interests focus on modeling video based structure and semantic formulation, such as Video Based Pose Estimation, Action Recognition and 
                Events Prediction, et.al,. Before I came to CUHK, I also did research on 2D/RGB-D Semantic Segmentation.
                </p>

                <br/>
                </p> 
                <br>
                <div>
                    <div id="news"><img src="images/icon/news.png" title="news" width="24" height="24"> News</div>
                    <div class="row work-block">
                        <ul>
                            <li>
                                2021.02 &nbsp; One paepr is accepetd by <a href="http://cvpr2021.thecvf.com" target="_blank">CVPR 2021</a>
                            </li>
                            <!-- 9-->
                            <li> 
                                2020.11 &nbsp; One paper is accepted by <a href="https://nips.cc/" target="_blank">NeurIPS 2020</a>.
                            </li>
                             <!-- 8-->
                            <!-- <li> 
                                2020.08 &nbsp; Our BiSeNet is <a href="https://zhuanlan.zhihu.com/p/166468385"> Top-17 cited among all papers in ECCV2018</a>.
                            </li> -->
                             <!-- 7-->
                            <li> 
                                2020.07 &nbsp; Three papers are accepted by <a href="https://eccv2020.eu/" target="_blank">ECCV 2020</a>.
                            </li> 
                            <!-- 6-->      
                            <li> 
                                2020.03 &nbsp; One paper is accepted by <a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR 2020</a>.
                            </li>
                            <!-- 5-->
                            <li> 
                                2019.08 &nbsp; Coming to <a href="http://mmlab.ie.cuhk.edu.hk/"> MMLab </a>.
                            </li>
                            <!-- 4-->
                            <li> 
                                2019.03 &nbsp; One paper is accepted by <a href="http://cvpr2019.thecvf.com/" target="_blank">CVPR 2019</a>.
                            </li>
                            <!-- 3-->
                            <li> 
                                2018.09 &nbsp; As a team member of Megvii(Face++) and R4D Team, we won the 1st place of COCO
                                 Panoptic Segmentation and Mapillary Panoptic Segmentation in the
                                  <a href="http://cocodataset.org/workshop/coco-mapillary-eccv-2018.html">COCO & Mapillary Panoptic Segmentation Challenge 2018</a>.
                                  <a href="https://mp.weixin.qq.com/s/K36j2JcTWPV1velUqyy6pA"><b>[ChinaNews]</b></a>
                            </li>
                            <!-- 2-->
                            <li> 
                                2018.07 &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/ECCV2018" target="_blank">ECCV 2018</a>.
                            </li> 
                            <!-- 1-->
                            <li> 
                                2018.03 &nbsp; One paper is accepted by <a href="http://cvpr2018.thecvf.com/" target="_blank">CVPR 2018</a>.
                            </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<div id="rows" style="margin-left: 8%">


<div id="publication">
    <div class="container">
        <h2 class="section_title">Selected Publications 
            <a href="https://scholar.google.co.uk/citations?user=GStTsxAAAAAJ&hl=en" target="_blank">
                    (<img src = "images/icon/scholar.jpg" title = "scholar" width ="28"> Google Scholar)
            </a>
        </h2>
        <!-- Paper Insubmission-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/Posegeneration/arch.png">
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>, Sijie Yan, Bo Dai, and Dahua Lin
                <br>
                <strong>Scene-aware Generative Network for Human Motion Synthesis </strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2021</em>
                <br>
                [<a href="wangjingbo1219.github.io/papers/Posegeneration/Posegeneration.html" target="_blank">Project</a>]
                [<a href="wangjingbo1219.github.io/papers/Posegeneration/01070.pdf" target="_blank">Paper</a>]
                [<a href="wangjingbo1219.github.io/papers/Posegeneration/01070-supp.pdf" target="_blank">Supp</a>]               
                [<a href="https://www.youtube.com/watch?v=XfA3QWcV0ik" target="_blank">Demo Video</a>]
                <br>
            </div>
        </div>
    <!-- Paper NIPS2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/NIPS2020_GroupEncodes/arch.png">
        </div>
        <div class="col-xs-8">
            Xu Liu, Chengtao Li, Jian Wang, <u>Jingbo Wang</u>, Boxin Shi, and Xiaodong He
            <br>
            <strong>Group Contextual Encoding for 3D Point Clouds </strong>
            <br>
            <em><i>Advances in Neural Information Processing Systems(<strong>NeurIPS</strong>)</i>, 2020</em>
            <br>
            [<a href="https://papers.nips.cc/paper/2020/hash/9b72e31dac81715466cd580a448cf823-Abstract.html" target="_blank">Paper</a>]
            [<a href="https://github.com/AsahiLiu/PointDetectron" target="_blank">Project</a>]
            <br>
        </div>
    </div>

    <!-- Paper ECCV 2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2020-Video-Pose/arch_1.png">
        </div>
        <div class="col-xs-8">
            <u>Jingbo Wang</u>, Sijie Yan, Yuanjun Xiong,and Dahua Lin
            <br>
            <strong>Motion Guided 3D Pose Estimation from Videos </strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/pdf/2004.13985.pdf" target="_blank">Paper</a>]
            [<a href="wangjingbo1219.github.io/papers/ECCV2020-Video-Pose/MotionLossPage.html" target="_blank">Project</a>]
            [<a href="https://www.youtube.com/watch?v=VHhsXG6OXnI" target="_blank">Demo Video</a>]
            <br>
        </div>
    </div>

    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2020_2.5D_Seg/arch.png">
        </div>
        <div class="col-xs-8">
            Yajie Xing, <u>Jingbo Wang</u>, and Gang Zeng
            <br>
            <strong>Malleable 2.5D Convolution: Learning Receptive Fields along the Depth-axis for RGB-D Scene Parsing</strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/pdf/2007.09365.pdf" target="_blank">Paper</a>]
            [<a href="https://github.com/charlesCXK/RGBD_Semantic_Segmentation_PyTorch" target="_blank">Project</a>]
            <br>
        </div>
    </div>

    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2020_RGBD_Seg/arch.png">
        </div>
        <div class="col-xs-8">
            Xiaokang Chen, Kwan-Yee Lin, <u>Jingbo Wang</u>, Wayne Wu, Chen Qian, Hongsheng Li, and Gang Zeng
            <br>
            <strong>Bi-directional Cross-Modality Feature Propagation with Separation-and-Aggregation Gate for RGB-D Semantic Segmentation</strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/pdf/2007.09183.pdf" target="_blank">Paper</a>]
            [<a href="https://github.com/charlesCXK/RGBD_Semantic_Segmentation_PyTorch" target="_blank">Project</a>]
            <br>
        </div>
    </div>

    <!-- Paper CVPR 2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/CVPR2020_CPN/arch.png">
        </div>

        <div class="col-xs-8">
            Changqian Yu, <u>Jingbo Wang</u>, Changxin Gao, Gangyu, Chunhua Shen and Nong Song
            <br>
            <strong>Context Prior for Scene Segmentation</strong>
            <br>
            <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2020</em>
            <br>
            [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yu_Context_Prior_for_Scene_Segmentation_CVPR_2020_paper.pdf" target="_blank">Paper</a>] 
            <br>
        </div>
    </div>

       <!-- Paper CVPR 2019 -->
       <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/CVPR2019_Panoptic/arch.png">
        </div>

        <div class="col-xs-8">
            Huanyu Liu, Chao Peng, Changqian Yu, <u>Jingbo Wang</u>, Xu Liu, Gang Yu, Wei Jiang
            <br>
            <strong>An End-to-End Network for Panoptic Segmentation</strong>
            <br>
            <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2019</em>
            <br>
            [<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_An_End-To-End_Network_for_Panoptic_Segmentation_CVPR_2019_paper.pdf" target="_blank">Paper</a>] 
            <br>
        </div>
    </div>

    <!-- Paper ECCV 2018 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2018_BiseNet/arch.png">
        </div>

        <div class="col-xs-8">
            Changqian Yu*, <u>Jingbo Wang*</u>, Chao Peng, Changxin Gao, Gang Yu and Nong Sang ('*' donates equal contribution.)
            <br>
            <strong>BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2018</em>
            <br>
            [<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.pdf" target="_blank">Paper</a>]
            [<a href="https://github.com/ycszen/TorchSeg" target="_blank">Project</a>]
            
            <br>
        </div>
    </div>

    <!-- Paper CVPR 2018 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/CVPR2018_DFN/arch.png">
        </div>

        <div class="col-xs-8">
            Changqian Yu, <u>Jingbo Wang</u>, Chao Peng, Changxin Gao, Gang Yu and Nong Sang 
            <br>
            <strong>Learning a Discriminative Feature Network for Semantic Segmentation</strong>
            <br>
            <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2018</em>
            <br>
            [<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Learning_a_Discriminative_CVPR_2018_paper.pdf" target="_blank">Paper</a>] 
            [<a href="https://github.com/ycszen/TorchSeg" target="_blank">Project</a>]
            <br>
        </div>
    </div>
</div>

<div id="education">
    <div class="container">
        <h2 class="section_title">Education</h2>
        <div class="row work-block">
            <ul>
                <li>[2020.08-Now] &nbsp; Ph.D student at MMLab, IE Department, The Chinese University of Hong Kong.
                <li>[2016.09-2019.07] &nbsp; Key Laboratory of Machine Perception (MOE), School of EECS, Peking University.
                <li>[2012.09-2016.07] &nbsp; Beijing Institute of Technology, School of Mathematics and Statistics.
            </ul>
        </div>
    </div>
</div>

<div id="experiences">
    <div class="container">
        <h2 class="section_title">Experiences</h2>
        <div class="row work-block">
            <ul>
                <li>[2020.1-now] &nbsp; Research Intern at <a href="https://www.sensetime.com/en/" target="_blank">SenseTime Research</a>. Supervised by <a href="https://scholar.google.com/citations?user=Dqjnn0gAAAAJ&hl=zh-CN">Mr. Ding Liang</a>.
                <li>[2019.8-2020.7] &nbsp; Research Assistant at <a href="http://mmlab.ie.cuhk.edu.hk/"> MMLab</a>. Supervised by <a href="http://dahua.me/"> Prof. Dahua Lin</a>.
                <li>[2019.1-2019.6] &nbsp; Research Intern at <a href="https://www.momenta.cn/"> Momenta</a>. Supervised by <a href="http://www.pengchao.org/">Mr. Chao Peng</a>.
                <li>[2017.6-2018.12] &nbsp; Research Intern at <a href="https://megvii.com/technologies/megvii_research?num=1"> Megvii Research</a>, R4D Group. Supervise by <a href="http://www.skicyyu.org/">Dr. Gang Yu</a>
            </ul>
        </div>
    </div>
</div>

<div id="academic competition">
<div class="container">
    <h2 class="section_title">Academic Competition</h2>
    <div class="row work-block">
        <ul>
            <li><div style="float:left; text-align:left"> <strong>Winner</strong> of COCO 2018 Challenge in Panoptic Segmentation Track </div> </li>
            <li><div style="float:left; text-align:left"> <strong>Winner</strong> of Mapillary 2018 Challenge in Panoptic Segmentation Track </div>
        </ul>
    </div>
</div>
</div>

<div id="professional activities">
    <div class="container">
        <h2 class="section_title">Professional Activities</h2>
        <div class="row work-block">
            <ul>
            <li>Conference Reviewer:</li>
            <dd><p>

                IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020. <br/>
                European Conference on Computer Vision (ECCV) 2020. <br/>
                Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI) 2020. <br/>
                Winter Conference on Applications of Computer Vision (WACV) 2020. <br/>
                Asian Conference on Computer Vision (ACCV) 2020. <br/>
                IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019. <br/>
                IEEE International Conference on Computer Vision (ICCV) 2019. <br/>
            </p></dd>
            <li>Journal Reviewer:</li>
            <dd><p>
            International Journal of Computer Vision (IJCV). <br /></p></dd>
            </dl>
            </ul>
        </div>
    </div>
</div>


<!-- <div id="honors">
    <div class="container">
        <h2 class="section_title">Selected Honors</h2>
        <div class="row work-block">
            <ul>
                <li>Award for Excellent Research, PKU, 2018-2019 </li>
                <li>Award for Academic Excellents, PKU, 2017-2018 </li>
            </ul>
        </div>
    </div>
</div> -->
<div id="footer">
    <div id="footer-text"></div>
</div>

<div style="float:center; text-align:center">
    Links:<a href='http://www.skicyyu.org/'>俞刚(Yu Gang)</a> &nbsp; 
    <a href='http://www.pengchao.org/'>彭超(Peng Chao)</a> &nbsp;
    <a href='http://changqianyu.me/'>余昌黔(Yu Changqian)</a> &nbsp;
    <a href='http://yjxiong.me/'>熊元骏(Xiong Yuanjun)</a> &nbsp;
    <a href='http://daibo.info'>戴勃(Dai Bo)</a> &nbsp;
    <a href='https://scholar.google.co.uk/citations?user=tAgSyxIAAAAJ&hl=en'>颜思捷(Yan Sijie)</a> &nbsp;
    <a href='https://charlescxk.github.io/'>陈小康(Chen Xiaokang)</a> &nbsp;
    <a href='https://xieenze.github.io/'>谢恩泽(Xie Enze)</a> &nbsp;
    <a href='https://cn.linkedin.com/in/亚杰-邢-1805a4a7'>邢亚杰(Xing Yajie)</a> &nbsp;


</div>

<div class="container footer">
    <div class="row">
        <div class="text-center">
        Jingbo Wang @2020 &nbsp;&nbsp;&nbsp;&nbsp; Total Visitors:
        <a href='https://www.counter12.com'><img src='https://www.counter12.com/img-xWZ216Z86zx2AZbb-77.gif' border='0' alt='web counter free'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=xWZ216Z86zx2AZbb'></script></div> 
    </div>
</div>



</body>
</html>
