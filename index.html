<!DOCTYPE html>

<html lang="en">
<head>
    <!-- Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://scholar.google.co.uk/citations?user=GStTsxAAAAAJ&hl=en"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-156699410-1');
    </script>
    
    <meta charset="UTF-8">
    <meta http-equiv="Content-Security-Policy" content="block-all-mixed-content">

    <title>Jingbo Wang 王靖博</title>
    <link rel="icon"  href="images/icon.jpeg" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="css/style.css">
</head>

<div class="navbar navbar-fixed-top">
    <div class="container">
        <strong class="navbar-brand">Jingbo Wang / 王靖博</strong>
        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="#about">About</a></li>
                <li><a href="#publication">Publications</a></li>
                <li><a href="#education">Education</a></li>
                <li><a href="#experiences">Experiences</a></li>
                <li><a href="#academic competition">Competition</a></li>
                <li><a href="#professional activities"> Activities</a></li>


                <!-- <li><a href="#honors">Honors</a></li> -->
            </ul>
        </div>
    </div>
</div>

<div class="gray-container" id="about">
    <div class="container">
        <div class="row">
            <div class="col-xs-4">
                <img id="me-img" src="images/jingbo.jpg" width='512'>

                <div style="margin-top: 10%; font-size: large";><strong>Jingbo Wang/ 王靖博</strong></div>
                <div style="margin-top: 5%"> Researcher at <a href="https://www.shlab.org.cn/">Shanghai AI Lab</a></div>
                <div style="margin-top: 5%">   <a href="mailto:wangjingbo1219@gmail.com">wangjingbo1219@gmail.com</a> </div>
            </div>
            <div class="col-xs-8">
                <h2>
                    <strong>Jingbo Wang</strong>
                    <a href="cv-homepage.pdf" target="_blank">
                        <img src = "images/icon/cv.png" title = "cv" width ="36" height = "36">
                    </a>
                </h2>

                <p>
                <img src="images/icon/education.png" title="education" width="24" height="24">  
                I obtained my Ph.D. from The Chinese University of Hong Kong (<a href="http://mmlab.ie.cuhk.edu.hk/"> MMLAB </a>), 
                supervised by <a href="http://dahua.me/"> Prof. Dahua Lin</a>. Before that, I received my Master degree from Peking University in 2019,
                supervised by <a href="https://scholar.google.com/citations?user=RuHyY6gAAAAJ&hl=zh-CN"> Prof. Gang Zeng</a>, and my Bachelor degree from Beijing Institute of Technology in July 2016.
                <br/>
                </p>

                <br/>
                <p>
                <img src="images/icon/thought.png" title="thoughts" width="24" height="24"> 
                I'm interested in computer vision, deep learning, generative AI, character animation, and embodied AI. 
                Most of my research is about generating realistic character animations as human in the real world.
                Before this, I also did research on scene understanding with efficient model (A.K.A BiseNet V1/V2) and multi-modality input.
                </p>

                <br/>
                </p> 
                <br>
                <div>
                    <div id="news"><img src="images/icon/news.png" title="news" width="24" height="24"> News</div>
                    <div class="row work-block">
                        <ul>
                            <li>
                             
                            </li>
                            <li>
                               Always looking for research interns with strong CV/CG/ML background. Recently, we are working on motion simulation for human/hand-scene interaction, next generation animation system, and 2D/3D character generation.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<div id="rows" style="margin-left: 8%">


<div id="publication">
    <div class="container">
        <h2 class="section_title">Selected Publications for Recent Interests
            <a href="https://scholar.google.co.uk/citations?user=GStTsxAAAAAJ&hl=en" target="_blank">
                    (<img src = "images/icon/scholar.jpg" title = "scholar" width ="28"> Full List in Google Scholar)
            </a>
        </h2>
        <!-- Paper PCACER+-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/CVPR2024_PACER_PLUS/cvpr_2024_sub.png", width=20%>
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>*, Zhengyi Luo*, Ye Yuan, Yixuan Li, Bo Dai ('*' donats equal contribution.)
                <br>
                <strong>PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios</strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2024</em>
                <br>
                [<a href="papers/CVPR2024_PACER_PLUS/PACERPLUSPage.html" target="_blank">Paper</a>]
                [<a href="papers/CVPR2024_PACER_PLUS/pacer_plus.pdf" target="_blank">Paper</a>]
                [<a href="papers/CVPR2024_PACER_PLUS/demo_1_compress.mp4" target="_blank">Video</a>]
                <br>
            </div>
        </div>
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/COMODO/comodo.png", width=20%>
            </div>
            <div class="col-xs-8">
                Yi Shi, <u>Jingbo Wang</u>, Xuekun Jiang, Bo Dai
                <br>
                <strong>Controllable Motion Diffusion Model</strong>
                <br>
                <!-- <em><i>The International Conference on Learning Representations (<strong>ICLR</strong>)</i>, 2024</em>
                <br> -->
                [<a href="https://arxiv.org/pdf/2306.00416.pdf" target="_blank">Paper</a>]
                [<a href="https://controllablemdm.github.io/" target="_blank">Project</a>]
                <br>
            </div>
        </div>

        <!-- Paper ICLR 2024-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/ICLR2024_COC/unihsi.png", width=20%>
            </div>
            <div class="col-xs-8">
                Zeqi Xiao, Tai Wang, <u>Jingbo Wang</u>, Jinkun Cao, Wenwei Zhang, Bo Dai, Dahua Lin, Jiangmiao Pang
                <br>
                <strong>Unified Human-Scene Interaction via Prompted Chain-of-Contacts</strong>
                <br>
                <em><i>The International Conference on Learning Representations (<strong>ICLR</strong>)</i>, 2024</em>
                <br>
                [<a href="https://github.com/OpenRobotLab/UniHSI/blob/main/assets/UniHSI.pdf" target="_blank">Paper</a>]
                [<a href="https://xizaoqu.github.io/unihsi/" target="_blank">Project</a>]
                <br>
            </div>
        </div>
        <!-- Paper 3DV 2024-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/3DV2024_Inter/3dv_2024.png", width=20%>
            </div>
            <div class="col-xs-8">
                Liang Pan, <u>Jingbo Wang</u>, Buzhen Huang, Junyu Zhang, Haofan Wang, Xu Tang, Yangang Wang
                <br>
                <strong>Synthesizing Physically Plausible Human Motions in 3D Scenes</strong>
                <br>
                <em><i>International Conference on 3D Vision (<strong>3DV</strong>)</i>, 2024</em>
                <br>
                [<a href="https://arxiv.org/abs/2308.09036" target="_blank">Paper</a>]
                [<a href="https://liangpan99.github.io/InterScene/" target="_blank">Project</a>]

                <br>
            </div>
        </div>
        <!-- Paper ICCV 2023-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/ICCV2023_Drive/iccv_2023.png", width=20%>
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>, Ye Yuan, Zhengyi Luo, Kevin Xie, Dahua Lin, Umar Iqbal,
                Sanja Fidler, Sameh Khamis
                <br>
                <strong>Learning Human Dynamics in Autonomous Driving Scenarios </strong>
                <br>
                <em><i>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2023</em>
                <br>
                [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.pdf" target="_blank">Paper</a>]
                [<a href="https://youtu.be/QTQtIDQVJ1I" target="_blank">Video</a>]

                <br>
            </div>
        </div>

        <!-- Paper CVPR 2022-->
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/CVPR2022_Motion/cvpr_2022.png", width=20%>
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>, Yu Rong, Jingyuan Liu, Sijie Yan, Dahua Lin, Bo Dai
                <br>
                <strong>Towards Diverse and Natural Scene-aware 3d Human Motion Synthesis </strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2022</em>
                <br>
                [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.pdf" target="_blank">Paper</a>]
                [<a href="https://www.youtube.com/watch?v=nOOVjflR0nM" target="_blank">Video</a>]

                <br>
            </div>
        </div>

        <!-- Paper 3DV 2021--> 
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/3DV2021_Hand/3dv.png", width=20%>
            </div>
            <div class="col-xs-8">
                Yu Rong, <u>Jingbo Wang</u>, Ziwei Liu, Chen Change Loy
                <br>
                <strong> Monocular 3D Reconstruction of Interacting Hands via Collision-Aware Factorized Refinements </strong>
                <br>
                <em><i>International Conference on 3D Vision (<strong>3DV</strong>)</i>, 2021</em>
                <br>
                [<a href="https://penincillin.github.io/ihmr_3dv2021" target="_blank">Project</a>]
                [<a href="https://arxiv.org/pdf/2111.00763.pdf" target="_blank">Paper</a>]
                <br>
            </div>
        </div>

       <!-- Paper CVPR2021--> 
        <div class="row work-block">
            <div class="project col-xs-3">
                <img class="work-img" src="papers/CVPR2021_PoseGeneration/arch.png", width=20%>
            </div>
            <div class="col-xs-8">
                <u>Jingbo Wang</u>, Sijie Yan, Bo Dai, and Dahua Lin
                <br>
                <strong>Scene-aware Generative Network for Human Motion Synthesis </strong>
                <br>
                <em><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, 2021</em>
                <br>
                [<a href="wangjingbo1219.github.io/papers/CVPR2021_PoseGeneration/Posegeneration.html" target="_blank">Project</a>]
                [<a href="wangjingbo1219.github.io/papers/CVPR2021_PoseGeneration/01070.pdf" target="_blank">Paper</a>]
                [<a href="wangjingbo1219.github.io/papers/CVPR2021_PoseGeneration/01070-supp.pdf" target="_blank">Supp</a>]               
                [<a href="https://www.youtube.com/watch?v=XfA3QWcV0ik" target="_blank">Demo Video</a>]
                <br>
            </div>
        </div>

    <!-- Paper ECCV 2020 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2020-Video-Pose/arch_1.png">
        </div>
        <div class="col-xs-8">
            <u>Jingbo Wang</u>, Sijie Yan, Yuanjun Xiong,and Dahua Lin
            <br>
            <strong>Motion Guided 3D Pose Estimation from Videos </strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2020</em>
            <br>
            [<a href="https://arxiv.org/pdf/2004.13985.pdf" target="_blank">Paper</a>]
            [<a href="wangjingbo1219.github.io/papers/ECCV2020-Video-Pose/MotionLossPage.html" target="_blank">Project</a>]
            [<a href="https://www.youtube.com/watch?v=VHhsXG6OXnI" target="_blank">Demo Video</a>]
            <br>
        </div>
    </div>
    <!-- Paper ECCV 2018 -->
    <div class="row work-block">
        <div class="project col-xs-3">
            <img class="work-img" src="papers/ECCV2018_BiseNet/arch.png">
        </div>

        <div class="col-xs-8">
            Changqian Yu*, <u>Jingbo Wang*</u>, Chao Peng, Changxin Gao, Gang Yu and Nong Sang ('*' donates equal contribution.)
            <br>
            <strong>BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</strong>
            <br>
            <em><i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, 2018</em>
            <br>
            [<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.pdf" target="_blank">BiSeNet</a>]
            [<a href="https://arxiv.org/pdf/2004.02147.pdf" target="blank">BiSeNetv2</a>]
            [<a href="https://github.com/ycszen/TorchSeg" target="_blank">Project</a>]
            
            <br>
        </div>
    </div>


<div id="education">
    <div class="container">
        <h2 class="section_title">Education</h2>
        <div class="row work-block">
            <ul>
                <li>[2020.08-2023.08] &nbsp; Ph.D student at MMLab, IE Department, The Chinese University of Hong Kong.
                <li>[2016.09-2019.07] &nbsp; Key Laboratory of Machine Perception (MOE), School of EECS, Peking University.
                <li>[2012.09-2016.07] &nbsp; Beijing Institute of Technology, School of Mathematics and Statistics.
            </ul>
        </div>
    </div>
</div>

<div id="experiences">
    <div class="container">
        <h2 class="section_title">Experiences</h2>
        <div class="row work-block">
            <ul>
                <li>[2022.05-2023.06] &nbsp; Research Intern at Nvidia Toronto AI Lab. Supervised by Dr Ye Yuan, Dr Sameh Khamis, and Prof. Sanja Filder</a>.
                <li>[2022.01-2022.05] &nbsp; Research Intern at Shanghai AI Lab. Supervised by Dr. Bo Dai</a>.
                <li>[2020.01-2021.12] &nbsp; Research Intern at SenseTime Research. Supervised by Dr. Ding Liang.
                <li>[2019.08-2020.07] &nbsp; Research Assistant at MMLAB, CUHK. Supervised by Prof. Dahua Lin.
                <li>[2017.06-2018.12] &nbsp; Research Intern at  Megvii Research. Supervise by Dr, Gang Yu.
            </ul>
        </div>
    </div>
</div>

<div id="academic competition">
<div class="container">
    <h2 class="section_title">Academic Competition</h2>
    <div class="row work-block">
        <ul>
            <li><div style="float:left; text-align:left"> <strong>Winner</strong> of COCO 2018 Challenge in Panoptic Segmentation Track </div> </li>
            <li><div style="float:left; text-align:left"> <strong>Winner</strong> of Mapillary 2018 Challenge in Panoptic Segmentation Track </div>
        </ul>
    </div>
</div>
</div>

<div id="professional activities">
    <div class="container">
        <h2 class="section_title">Professional Activities</h2>
        <div class="row work-block">
            <ul>
            <li>Conference Reviewer:</li>
            <dd><p>
                CVPR, ICCV, ECCV, SIGGRAPH, ICML, ICLR, NeurIPS, AAAI, 3DV.
            </p></dd>
            <li>Journal Reviewer:</li>
            <dd><p>
            IJCV, T-PAMI. <br /></p></dd>
            </dl>
            </ul>
        </div>
    </div>
</div>


<!-- <div id="honors">
    <div class="container">
        <h2 class="section_title">Selected Honors</h2>
        <div class="row work-block">
            <ul>
                <li>Award for Excellent Research, PKU, 2018-2019 </li>
                <li>Award for Academic Excellents, PKU, 2017-2018 </li>
            </ul>
        </div>
    </div>
</div> -->
<div id="footer">
    <div id="footer-text"></div>
</div>

<!-- <div style="float:center; text-align:center">
    Links:<a href='http://www.skicyyu.org/'>俞刚(Yu Gang)</a> &nbsp; 
    <a href='http://yjxiong.me/'>熊元骏(Xiong Yuanjun)</a> &nbsp;
    <a href='http://daibo.info'>戴勃(Dai Bo)</a> &nbsp;
    <a href='http://www.pengchao.org/'>彭超(Peng Chao)</a> &nbsp;
    <a href='http://changqianyu.me/'>余昌黔(Yu Changqian)</a> &nbsp;<br>
    <a href='https://scholar.google.co.uk/citations?user=tAgSyxIAAAAJ&hl=en'>颜思捷(Yan Sijie)</a> &nbsp;
    <a href='https://charlescxk.github.io/'>陈小康(Chen Xiaokang)</a> &nbsp;
    <a href='https://xieenze.github.io/'>谢恩泽(Xie Enze)</a> &nbsp;
    <a href='https://cn.linkedin.com/in/亚杰-邢-1805a4a7'>邢亚杰(Xing Yajie)</a> &nbsp;


</div> -->

<div class="container footer">
    <div class="row">
        <div class="text-center">
        Jingbo Wang @2020 &nbsp;&nbsp;&nbsp;&nbsp; Total Visitors:
        <a href='https://www.counter12.com'><img src='https://www.counter12.com/img-xWZ216Z86zx2AZbb-77.gif' border='0' alt='web counter free'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=xWZ216Z86zx2AZbb'></script></div> 
    </div>
</div>



</body>
</html>
